{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 23:39:12.888951: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-20 23:39:13.747799: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/weap/masters_degree/masters_degree_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Bidirectional, RepeatVector, Attention, Concatenate, Conv1D, MaxPooling1D, Concatenate, UpSampling1D, MultiHeadAttention, LayerNormalization, Add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "from datasets import load_dataset\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"embedding-data/simple-wiki\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The greatest example has been in his present job ( then , Minister for Foreign Affairs ) , where he has perforce concentrated on Anglo-Irish relations and , in particular Northern Ireland ( .\n",
      "The greatest example has been in his present job ( then , Minister for Foreign Affairs ) , where he has perforce concentrated on Anglo-Irish relations and , in particular the North ( i.e. , Northern Ireland ) .\n",
      "President Hillery refused to speak to any opposition party politicians , but when Charles Haughey , who was Leader of the Opposition , had rang the President 's Office he threatened to end the career of the army officer answered and refused on Hillery 's explicit orders to put the call through to the President .\n",
      "His reputation rose further when opposition leaders under parliamentary privilege alleged that Taoiseach Charles Haughey , who in January 1982 had been Leader of the Opposition , had not merely rung the President 's Office but threatened to end the career of the army officer who took the call and who , on Hillery 's explicit instructions , had refused to put through the call to the President .\n",
      "He thought about returning to medicine , perhaps moving with his wife , Maeve ( also a doctor ) to Africa .\n",
      "He considered returning to medicine , perhaps moving with his wife , Maeve ( also a doctor ) to Africa .\n",
      "Hillery 's most famous policy was to force EEC member states to give equal pay to women .\n",
      "As Social Affairs Commissioner Hillery 's most famous policy initiative was to force EEC member states to give equal pay to women .\n",
      "When President Cearbhall Ã `` DÃ laigh resigned , Hillery agreed to become the Fianna FÃ il candidate in the election .\n",
      "When a furious President Ã `` DÃ laigh resigned , a deeply reluctant Hillery agreed to become the Fianna FÃ il candidate for the presidency .\n"
     ]
    }
   ],
   "source": [
    "train_data = dataset['train']\n",
    "sentences = [sentence for pair in train_data['set'] for sentence in pair]\n",
    "for i in range(10):\n",
    "    print(sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Tukatongue Thallid', 'Moriok Replica', 'Faerie Mechanist', ...,\n",
       "        'Mogg Squad', 'Roots of Wisdom', 'Raven Guild Master'],\n",
       "       dtype=object),\n",
       " array(['When Tukatongue Thallid dies, create a 1/1 green Saproling creature token.1.011Creature — Fungus',\n",
       "        '{1}{B}, Sacrifice Moriok Replica: You draw two cards and you lose 2 life.3.022Artifact Creature — Warrior',\n",
       "        'Flying\\nWhen Faerie Mechanist enters the battlefield, look at the top three cards of your library. You may reveal an artifact card from among them and put it into your hand. Put the rest on the bottom of your library in any order.4.022Artifact Creature — Faerie Artificer',\n",
       "        ...,\n",
       "        'Mogg Squad gets -1/-1 for each other creature on the battlefield.2.033Creature — Goblin',\n",
       "        \"Mill three cards, then return a land card or Elf card from your graveyard to your hand. If you can't, draw a card. (To mill a card, put the top card of your library into your graveyard.)2.0nannanSorcery\",\n",
       "        'Whenever Raven Guild Master deals combat damage to a player, that player exiles the top ten cards of their library.\\nMorph {2}{U}{U} (You may cast this card face down as a 2/2 creature for {3}. Turn it face up any time for its morph cost.)3.011Creature — Human Wizard Mutant'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = 'data_download/MyDataMTGv2.json'\n",
    "\n",
    "\n",
    "def load_dataset(path):\n",
    "    df = pd.read_json(path).T\n",
    "    df['text'] = df['text'].astype(str).fillna('text')\n",
    "    df['manaValue'] = df['manaValue'].astype(str).fillna('manaValue')\n",
    "    df['toughness'] = df['toughness'].astype(str).fillna('toughness')\n",
    "    df['power'] = df['power'].astype(str).fillna('power')\n",
    "    df['type'] = df['type'].astype(str).fillna('type')\n",
    "    df['description'] = df['text'] + '' + df['manaValue'] + '' + df['toughness'] + '' + df['power'] + '' + df['type']\n",
    "    df_filtered = df[['description']].reset_index()\n",
    "    df_filtered.rename(columns={'index': 'card_name'}, inplace=True)\n",
    "    return df_filtered['card_name'].values, df_filtered['description'].values\n",
    "\n",
    "card_names, card_descriptions = load_dataset(filepath)\n",
    "\n",
    "card_names, card_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 512\n",
    "max_len_description = 50 \n",
    "max_len_name = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and padding\n",
    "tokenizer_sentences = Tokenizer(char_level=True,\n",
    "                      lower=True,\n",
    "                      filters='!\"#$%&()*,.:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "                    #   filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "\n",
    "tokenizer_card_descriptions= Tokenizer(char_level=True,\n",
    "                             lower=True,\n",
    "                             filters='!\"#$%&()*,.:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "                    #   filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "\n",
    "tokenizer_sentences.fit_on_texts(sentences)\n",
    "sequences_sentences = tokenizer_sentences.texts_to_sequences(sentences)\n",
    "padded_sequences_sentences = pad_sequences(sequences_sentences, maxlen=max_len_description, padding='post')\n",
    "\n",
    "tokenizer_card_descriptions.fit_on_texts(card_descriptions)\n",
    "sequences_card_descriptions = tokenizer_card_descriptions.texts_to_sequences(card_descriptions)\n",
    "padded_sequences_card_descriptions = pad_sequences(sequences_card_descriptions, maxlen=max_len_description, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer_sentences.word_index) + 1  # Plus 1 for padding\n",
    "\n",
    "padded_sequences_sentences = np.array(padded_sequences_sentences)\n",
    "target_padded_sequences_sentences= np.expand_dims(padded_sequences_sentences, -1)\n",
    "\n",
    "padded_sequences_card_descriptions = np.array(padded_sequences_card_descriptions)\n",
    "target_padded_sequences_card_descriptions= np.expand_dims(padded_sequences_card_descriptions, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tokenizer(tokenizer, path='./models/tokenizer.pkl'):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(tokenizer, f)\n",
    "\n",
    "def load_tokenizer(path='./models/tokenizer.pkl'):\n",
    "    with open(path, 'rb') as f:\n",
    "        tokenizer = pickle.load(f)\n",
    "    return tokenizer\n",
    "\n",
    "save_tokenizer(tokenizer_card_descriptions)\n",
    "tokenizer_card_descriptions = load_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, name, path='./models'):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    model.save(os.path.join(path, f\"{name}.keras\"))\n",
    "\n",
    "def load_model(name, path='./models_copy'):\n",
    "    return tf.keras.models.load_model(os.path.join(path, f\"{name}.keras\"))\n",
    "\n",
    "autoencoder_skip_loaded = load_model(\"lstm_autoencoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(vocab_size, input_length, embedding_dim):\n",
    "    # Encoder\n",
    "    input_text = Input(shape=(input_length,))\n",
    "    x = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_text)\n",
    "    x = LSTM(embedding_dim, return_sequences=False)(x)\n",
    "    \n",
    "    # Dense layer as the \"bottleneck\" embedding (this is our sentence embedding)\n",
    "    encoded = Dense(embedding_dim, activation='relu')(x)\n",
    "    \n",
    "    # Decoder\n",
    "    x = Dense(embedding_dim, activation='relu')(encoded)\n",
    "    x = tf.keras.layers.RepeatVector(input_length)(x)\n",
    "    x = LSTM(embedding_dim, return_sequences=True)(x)\n",
    "    decoded = Dense(vocab_size, activation='softmax')(x)\n",
    "    \n",
    "    # Autoencoder model\n",
    "    autoencoder = Model(inputs=input_text, outputs=decoded)\n",
    "    \n",
    "    # Encoder model (for extracting embeddings)\n",
    "    encoder = Model(inputs=input_text, outputs=encoded)\n",
    "    \n",
    "    return autoencoder, encoder\n",
    "\n",
    "\n",
    "def create_skip_connection_autoencoder(vocab_size, input_length, embedding_dim):\n",
    "    # Encoder\n",
    "    input_text = Input(shape=(input_length,))\n",
    "    x = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_text)\n",
    "    skip1 = LSTM(embedding_dim, return_sequences=True)(x)  # First LSTM layer\n",
    "    skip2 = LSTM(embedding_dim, return_sequences=False)(skip1)  # Second LSTM layer\n",
    "    \n",
    "    # Bottleneck\n",
    "    encoded = Dense(embedding_dim, activation='relu')(skip2)\n",
    "    \n",
    "    # Decoder\n",
    "    x = Dense(embedding_dim, activation='relu')(encoded)\n",
    "    x = RepeatVector(input_length)(x)\n",
    "    x = LSTM(embedding_dim, return_sequences=True)(x)\n",
    "    \n",
    "    # Skip connections\n",
    "    x = Concatenate()([x, skip1])  # Skip connection from first encoder LSTM layer\n",
    "    x = LSTM(embedding_dim, return_sequences=True)(x)\n",
    "    decoded = Dense(vocab_size, activation='softmax')(x)\n",
    "    \n",
    "    # Models\n",
    "    autoencoder = Model(inputs=input_text, outputs=decoded)\n",
    "    encoder = Model(inputs=input_text, outputs=encoded)\n",
    "    \n",
    "    return autoencoder, encoder\n",
    "\n",
    "\n",
    "def create_bilstm_autoencoder(vocab_size, input_length, embedding_dim):\n",
    "    # Encoder\n",
    "    input_text = Input(shape=(input_length,))\n",
    "    x = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_text)\n",
    "    x = Bidirectional(LSTM(embedding_dim, return_sequences=False))(x)\n",
    "    \n",
    "    # Bottleneck\n",
    "    encoded = Dense(embedding_dim, activation='relu')(x)\n",
    "    \n",
    "    # Decoder\n",
    "    x = Dense(embedding_dim, activation='relu')(encoded)\n",
    "    x = RepeatVector(input_length)(x)\n",
    "    x = Bidirectional(LSTM(embedding_dim, return_sequences=True))(x)\n",
    "    decoded = Dense(vocab_size, activation='softmax')(x)\n",
    "    \n",
    "    # Models\n",
    "    autoencoder = Model(inputs=input_text, outputs=decoded)\n",
    "    encoder = Model(inputs=input_text, outputs=encoded)\n",
    "    \n",
    "    return autoencoder, encoder\n",
    "\n",
    "\n",
    "def create_bilstm_autoencoder_attention(vocab_size, input_length, embedding_dim):\n",
    "    # Encoder\n",
    "    input_text = Input(shape=(input_length,))\n",
    "    x = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_text)\n",
    "    \n",
    "    # Bidirectional LSTM for richer context encoding\n",
    "    x = Bidirectional(LSTM(embedding_dim, return_sequences=True))(x)\n",
    "    \n",
    "    # Adding a Dropout layer to prevent overfitting\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # Attention layer to focus on important words for MTG cards\n",
    "    # We calculate attention on the output of the LSTM\n",
    "    attention = Attention()([x, x])\n",
    "    x = Concatenate()([x, attention])  # Concatenate original LSTM output with attention output\n",
    "    \n",
    "    # Final dense layer as bottleneck embedding (sentence embedding)\n",
    "    x = LSTM(embedding_dim, return_sequences=False)(x)  # Flatten output for dense layer\n",
    "    encoded = Dense(embedding_dim, activation='relu')(x)\n",
    "    \n",
    "    # Decoder\n",
    "    x = Dense(embedding_dim, activation='relu')(encoded)\n",
    "    x = RepeatVector(input_length)(x)\n",
    "    \n",
    "    # Second LSTM layer for decoding\n",
    "    x = Bidirectional(LSTM(embedding_dim, return_sequences=True))(x)\n",
    "    x = Dropout(0.2)(x)  # Dropout in decoder for robustness\n",
    "    \n",
    "    # Final output layer with softmax activation\n",
    "    decoded = Dense(vocab_size, activation='softmax')(x)\n",
    "    \n",
    "    # Autoencoder model\n",
    "    autoencoder = Model(inputs=input_text, outputs=decoded)\n",
    "    \n",
    "    # Encoder model (for extracting embeddings)\n",
    "    encoder = Model(inputs=input_text, outputs=encoded)\n",
    "    \n",
    "    return autoencoder, encoder\n",
    "\n",
    "\n",
    "def create_cnn_lstm_autoencoder(vocab_size, input_length, embedding_dim):\n",
    "    # Encoder\n",
    "    input_text = Input(shape=(input_length,))\n",
    "    x = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_text)\n",
    "    x = Conv1D(embedding_dim, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = LSTM(embedding_dim, return_sequences=False)(x)\n",
    "    \n",
    "    # Bottleneck\n",
    "    encoded = Dense(embedding_dim, activation='relu')(x)\n",
    "    \n",
    "    # Decoder\n",
    "    x = Dense(embedding_dim, activation='relu')(encoded)\n",
    "    x = RepeatVector(input_length // 2)(x)\n",
    "    x = LSTM(embedding_dim, return_sequences=True)(x)\n",
    "    x = UpSampling1D(size=2)(x)\n",
    "    decoded = Dense(vocab_size, activation='softmax')(x)\n",
    "    \n",
    "    # Models\n",
    "    autoencoder = Model(inputs=input_text, outputs=decoded)\n",
    "    encoder = Model(inputs=input_text, outputs=encoded)\n",
    "    \n",
    "    return autoencoder, encoder\n",
    "\n",
    "\n",
    "def transformer_encoder_decoder(vocab_size, input_length, embedding_dim, num_heads=4):\n",
    "    # Encoder\n",
    "    input_text = Input(shape=(input_length,))\n",
    "    x = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_text)\n",
    "    x = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim)(x, x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = LSTM(embedding_dim, return_sequences=False)(x)\n",
    "    \n",
    "    # Bottleneck\n",
    "    encoded = Dense(embedding_dim, activation='relu')(x)\n",
    "    \n",
    "    # Decoder\n",
    "    x = Dense(embedding_dim, activation='relu')(encoded)\n",
    "    x = RepeatVector(input_length)(x)\n",
    "    x = LSTM(embedding_dim, return_sequences=True)(x)\n",
    "    decoded = Dense(vocab_size, activation='softmax')(x)\n",
    "    \n",
    "    # Models\n",
    "    autoencoder = Model(inputs=input_text, outputs=decoded)\n",
    "    encoder = Model(inputs=input_text, outputs=encoded)\n",
    "    \n",
    "    return autoencoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss',    \n",
    "    patience=5,\n",
    "    min_delta=0.1,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"lstm\", \"skip_connection_autoencoder\", \"bilstm\", \"bilstm_attention\", \"cnn_lstm\", \"transformer\"]\n",
    "model_functions = [create_lstm_model, create_skip_connection_autoencoder, create_bilstm_autoencoder, create_bilstm_autoencoder_attention, create_cnn_lstm_autoencoder, transformer_encoder_decoder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: lstm\n",
      "Epoch 1/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m884s\u001b[0m 552ms/step - loss: 2.8966\n",
      "Epoch 2/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m885s\u001b[0m 554ms/step - loss: 2.3175\n",
      "Epoch 3/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m887s\u001b[0m 555ms/step - loss: 1.8510\n",
      "Epoch 4/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m888s\u001b[0m 556ms/step - loss: 1.5034\n",
      "Epoch 5/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m890s\u001b[0m 557ms/step - loss: 1.2589\n",
      "Epoch 6/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m891s\u001b[0m 558ms/step - loss: 1.0951\n",
      "Epoch 7/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m891s\u001b[0m 558ms/step - loss: 0.9837\n",
      "Epoch 8/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m893s\u001b[0m 559ms/step - loss: 0.9576\n",
      "Epoch 9/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m893s\u001b[0m 559ms/step - loss: 0.8248\n",
      "Epoch 10/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m893s\u001b[0m 559ms/step - loss: 0.7333\n",
      "Epoch 11/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m892s\u001b[0m 558ms/step - loss: 0.7278\n",
      "Epoch 12/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m893s\u001b[0m 559ms/step - loss: 0.6719\n",
      "Epoch 13/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m892s\u001b[0m 558ms/step - loss: 0.6945\n",
      "Epoch 14/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m893s\u001b[0m 559ms/step - loss: 0.5333\n",
      "Epoch 15/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m894s\u001b[0m 559ms/step - loss: 0.6383\n",
      "Epoch 16/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m894s\u001b[0m 560ms/step - loss: 0.4998\n",
      "Epoch 17/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m894s\u001b[0m 559ms/step - loss: 0.4953\n",
      "Epoch 18/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m894s\u001b[0m 559ms/step - loss: 0.4530\n",
      "Epoch 19/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m894s\u001b[0m 559ms/step - loss: 0.3972\n",
      "Epoch 20/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m895s\u001b[0m 560ms/step - loss: 0.4527\n",
      "Epoch 21/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m895s\u001b[0m 560ms/step - loss: 0.4923\n",
      "Epoch 22/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m895s\u001b[0m 560ms/step - loss: 0.3891\n",
      "Epoch 23/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m895s\u001b[0m 560ms/step - loss: 0.3350\n",
      "Training Time: 20513.20 seconds\n",
      "Fine tunning:\n",
      "Epoch 1/10\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 288ms/step - loss: 1.1446\n",
      "Epoch 2/10\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 289ms/step - loss: 0.5565\n",
      "Epoch 3/10\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 290ms/step - loss: 0.4570\n",
      "Epoch 4/10\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 289ms/step - loss: 0.5279\n",
      "Epoch 5/10\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 291ms/step - loss: 0.3947\n",
      "Fine tunning: 1182.45 seconds\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Similar cards to Sol Ring:\n",
      "Sol Ring, (similarity: 1.00)\n",
      "Ur-Golem's Eye, (similarity: 1.00)\n",
      "Ur-Golem's Eye, (similarity: 1.00)\n",
      "Thran Dynamo, (similarity: 0.95)\n",
      "Wastes, (similarity: 0.92)\n",
      "Drake-Skull Cameo, (similarity: 0.92)\n",
      "Seashell Cameo, (similarity: 0.92)\n",
      "Troll-Horn Cameo, (similarity: 0.92)\n",
      "Tigereye Cameo, (similarity: 0.91)\n",
      "Bloodstone Cameo, (similarity: 0.91)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Similar cards to Structural Assault:\n",
      "Structural Assault, (similarity: 1.00)\n",
      "Thrilling Encore, (similarity: 0.98)\n",
      "Fresh Meat, (similarity: 0.97)\n",
      "Second Sunrise, (similarity: 0.97)\n",
      "Urborg Justice, (similarity: 0.97)\n",
      "Faith's Reward, (similarity: 0.97)\n",
      "Fatal Push, (similarity: 0.96)\n",
      "Let the Galaxy Burn, (similarity: 0.96)\n",
      "Force of Despair, (similarity: 0.94)\n",
      "Cradle to Grave, (similarity: 0.94)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Similar cards to Crossbow Ambush:\n",
      "Vines of the Recluse, (similarity: 1.00)\n",
      "Silk Net, (similarity: 1.00)\n",
      "Shape the Sands, (similarity: 1.00)\n",
      "Silk Net, (similarity: 1.00)\n",
      "Crossbow Ambush, (similarity: 1.00)\n",
      "Spidery Grasp, (similarity: 1.00)\n",
      "Gloomwidow's Feast, (similarity: 1.00)\n",
      "Aim High, (similarity: 1.00)\n",
      "Treetop Defense, (similarity: 1.00)\n",
      "Into the Fae Court, (similarity: 0.91)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Similar cards to Mephitic Draught:\n",
      "Mephitic Draught, (similarity: 1.00)\n",
      "Metalspinner's Puzzleknot, (similarity: 1.00)\n",
      "Infernal Idol, (similarity: 0.94)\n",
      "Dragon's Claw, (similarity: 0.91)\n",
      "Skeletal Scrying, (similarity: 0.91)\n",
      "Cut of the Profits, (similarity: 0.90)\n",
      "Tithing Blade // Consuming Sepulcher, (similarity: 0.90)\n",
      "Kraken's Eye, (similarity: 0.89)\n",
      "Golem's Heart, (similarity: 0.89)\n",
      "Geth's Grimoire, (similarity: 0.89)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Similar cards to Sangromancer:\n",
      "Sangromancer, (similarity: 1.00)\n",
      "Bloodrite Invoker, (similarity: 0.96)\n",
      "Kalastria Highborn, (similarity: 0.95)\n",
      "Sanctum Seeker, (similarity: 0.93)\n",
      "Herald of the Pantheon, (similarity: 0.93)\n",
      "Inspiring Cleric, (similarity: 0.93)\n",
      "Acolyte of Aclazotz, (similarity: 0.93)\n",
      "Centaur Healer, (similarity: 0.92)\n",
      "Judge of Currents, (similarity: 0.91)\n",
      "Apothecary Initiate, (similarity: 0.91)\n",
      "Model: skip_connection_autoencoder\n",
      "Epoch 1/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1994s\u001b[0m 1s/step - loss: 0.3726\n",
      "Epoch 2/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1995s\u001b[0m 1s/step - loss: 9.7756e-05\n",
      "Epoch 3/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1994s\u001b[0m 1s/step - loss: 4.0595e-05\n",
      "Epoch 4/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1995s\u001b[0m 1s/step - loss: 4.3715e-05\n",
      "Epoch 5/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2005s\u001b[0m 1s/step - loss: 1.8927e-05\n",
      "Epoch 6/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1952s\u001b[0m 1s/step - loss: 1.0153e-05\n",
      "Training Time: 11934.69 seconds\n",
      "Fine tunning:\n",
      "Epoch 1/10\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m551s\u001b[0m 674ms/step - loss: 3.1039e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m545s\u001b[0m 667ms/step - loss: 3.0237e-05\n",
      "Epoch 3/10\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m546s\u001b[0m 668ms/step - loss: 2.2909e-05\n",
      "Epoch 4/10\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m546s\u001b[0m 669ms/step - loss: 3.8585e-06\n",
      "Epoch 5/10\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m547s\u001b[0m 669ms/step - loss: 2.1014e-06\n",
      "Fine tunning: 2735.04 seconds\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Similar cards to Sol Ring:\n",
      "Ur-Golem's Eye, (similarity: 1.00)\n",
      "Ur-Golem's Eye, (similarity: 1.00)\n",
      "Sol Ring, (similarity: 1.00)\n",
      "Ardenvale Tactician // Dizzying Swoop, (similarity: 1.00)\n",
      "Jace's Ingenuity, (similarity: 1.00)\n",
      "Battle Hurda, (similarity: 1.00)\n",
      "Giant Warthog, (similarity: 1.00)\n",
      "Alpha Tyrranax, (similarity: 1.00)\n",
      "Coral Commando, (similarity: 1.00)\n",
      "Headwater Sentries, (similarity: 1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Similar cards to Structural Assault:\n",
      "Nahiri's Wrath, (similarity: 1.00)\n",
      "Temporal Manipulation, (similarity: 1.00)\n",
      "Noxious Vapors, (similarity: 1.00)\n",
      "Capital Punishment, (similarity: 1.00)\n",
      "Last Night Together, (similarity: 1.00)\n",
      "Praetor's Grasp, (similarity: 1.00)\n",
      "Pain's Reward, (similarity: 1.00)\n",
      "Hunger of the Nim, (similarity: 1.00)\n",
      "Allied Reinforcements, (similarity: 1.00)\n",
      "Makindi Stampede // Makindi Mesas, (similarity: 1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Similar cards to Crossbow Ambush:\n",
      "Closing Statement, (similarity: 1.00)\n",
      "Stern Scolding, (similarity: 1.00)\n",
      "Sauron's Ransom, (similarity: 1.00)\n",
      "Tribute to the Wild, (similarity: 1.00)\n",
      "Invert the Skies, (similarity: 1.00)\n",
      "Battle-Rage Blessing, (similarity: 1.00)\n",
      "Nightmare's Thirst, (similarity: 1.00)\n",
      "Dream Twist, (similarity: 1.00)\n",
      "Deflection, (similarity: 1.00)\n",
      "Momentous Fall, (similarity: 1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Similar cards to Mephitic Draught:\n",
      "Crystal Shard, (similarity: 1.00)\n",
      "Grindclock, (similarity: 1.00)\n",
      "Eye of Ramos, (similarity: 1.00)\n",
      "Colfenor's Urn, (similarity: 1.00)\n",
      "Cogworker's Puzzleknot, (similarity: 1.00)\n",
      "Selesnya Locket, (similarity: 1.00)\n",
      "Orzhov Keyrune, (similarity: 1.00)\n",
      "Goblin Charbelcher, (similarity: 1.00)\n",
      "Flowstone Armor, (similarity: 1.00)\n",
      "Mimic Vat, (similarity: 1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Similar cards to Sangromancer:\n",
      "Malakir Bloodwitch, (similarity: 1.00)\n",
      "Bloodhusk Ritualist, (similarity: 1.00)\n",
      "Vampire Hexmage, (similarity: 1.00)\n",
      "Pawn of Ulamog, (similarity: 1.00)\n",
      "Bloodrite Invoker, (similarity: 1.00)\n",
      "Vampire Nighthawk, (similarity: 1.00)\n",
      "Kalastria Highborn, (similarity: 1.00)\n",
      "Anowon, the Ruin Sage, (similarity: 1.00)\n",
      "Null Caller, (similarity: 1.00)\n",
      "Patron of the Vein, (similarity: 1.00)\n",
      "Model: bilstm\n",
      "Epoch 1/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1820s\u001b[0m 1s/step - loss: 2.6176\n",
      "Epoch 2/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1817s\u001b[0m 1s/step - loss: 1.5148\n",
      "Epoch 3/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1818s\u001b[0m 1s/step - loss: 1.1160\n",
      "Epoch 4/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1818s\u001b[0m 1s/step - loss: 0.8975\n",
      "Epoch 5/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1819s\u001b[0m 1s/step - loss: 0.7355\n",
      "Training Time: 9092.86 seconds\n",
      "Fine tunning:\n",
      "Epoch 1/10\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m571s\u001b[0m 699ms/step - loss: 1.6854\n",
      "Epoch 2/10\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m566s\u001b[0m 693ms/step - loss: 1.0567\n",
      "Epoch 3/10\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m567s\u001b[0m 695ms/step - loss: 0.8614\n",
      "Epoch 4/10\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m569s\u001b[0m 696ms/step - loss: 0.7658\n",
      "Epoch 5/10\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m568s\u001b[0m 695ms/step - loss: 0.6462\n",
      "Fine tunning: 2841.57 seconds\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 85ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Similar cards to Sol Ring:\n",
      "Sol Ring, (similarity: 1.00)\n",
      "Ur-Golem's Eye, (similarity: 1.00)\n",
      "Ur-Golem's Eye, (similarity: 1.00)\n",
      "Thran Dynamo, (similarity: 0.95)\n",
      "Kozilek's Channeler, (similarity: 0.93)\n",
      "Bloodstone Cameo, (similarity: 0.92)\n",
      "Seashell Cameo, (similarity: 0.92)\n",
      "Troll-Horn Cameo, (similarity: 0.92)\n",
      "Tigereye Cameo, (similarity: 0.91)\n",
      "Tree of Tales, (similarity: 0.90)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Similar cards to Structural Assault:\n",
      "Structural Assault, (similarity: 1.00)\n",
      "Fresh Meat, (similarity: 0.93)\n",
      "Thrilling Encore, (similarity: 0.93)\n",
      "Urborg Justice, (similarity: 0.92)\n",
      "Second Sunrise, (similarity: 0.91)\n",
      "Faith's Reward, (similarity: 0.91)\n",
      "Let the Galaxy Burn, (similarity: 0.90)\n",
      "Fatal Push, (similarity: 0.89)\n",
      "Force of Despair, (similarity: 0.83)\n",
      "Cradle to Grave, (similarity: 0.82)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Similar cards to Crossbow Ambush:\n",
      "Shape the Sands, (similarity: 1.00)\n",
      "Silk Net, (similarity: 1.00)\n",
      "Crossbow Ambush, (similarity: 1.00)\n",
      "Vines of the Recluse, (similarity: 1.00)\n",
      "Silk Net, (similarity: 1.00)\n",
      "Aim High, (similarity: 0.99)\n",
      "Treetop Defense, (similarity: 0.99)\n",
      "Spidery Grasp, (similarity: 0.99)\n",
      "Gloomwidow's Feast, (similarity: 0.99)\n",
      "Clip Wings, (similarity: 0.84)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Similar cards to Mephitic Draught:\n",
      "Metalspinner's Puzzleknot, (similarity: 1.00)\n",
      "Mephitic Draught, (similarity: 1.00)\n",
      "Skeletal Scrying, (similarity: 0.90)\n",
      "Cut of the Profits, (similarity: 0.88)\n",
      "Tithing Blade // Consuming Sepulcher, (similarity: 0.86)\n",
      "Plumb the Forbidden, (similarity: 0.85)\n",
      "Relic Vial, (similarity: 0.84)\n",
      "Dragon's Claw, (similarity: 0.83)\n",
      "Infernal Idol, (similarity: 0.83)\n",
      "Angel's Feather, (similarity: 0.82)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Similar cards to Sangromancer:\n",
      "Sangromancer, (similarity: 1.00)\n",
      "Bloodrite Invoker, (similarity: 0.93)\n",
      "Kalastria Highborn, (similarity: 0.91)\n",
      "Judge of Currents, (similarity: 0.86)\n",
      "Bog-Strider Ash, (similarity: 0.85)\n",
      "Herald of the Pantheon, (similarity: 0.85)\n",
      "Guardian of Cloverdell, (similarity: 0.82)\n",
      "Chambered Nautilus, (similarity: 0.81)\n",
      "Centaur Safeguard, (similarity: 0.80)\n",
      "Fallowsage, (similarity: 0.79)\n",
      "Model: bilstm_attention\n",
      "Epoch 1/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3178s\u001b[0m 2s/step - loss: 2.7016\n",
      "Epoch 2/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3215s\u001b[0m 2s/step - loss: 1.9976\n",
      "Epoch 3/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3224s\u001b[0m 2s/step - loss: 1.7362\n",
      "Epoch 4/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3224s\u001b[0m 2s/step - loss: 1.5618\n",
      "Epoch 5/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3222s\u001b[0m 2s/step - loss: 1.4463\n",
      "Training Time: 16062.60 seconds\n",
      "Fine tunning:\n",
      "Epoch 1/10\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1025s\u001b[0m 1s/step - loss: 2.0473\n",
      "Epoch 2/10\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1026s\u001b[0m 1s/step - loss: 1.5372\n",
      "Epoch 3/10\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1025s\u001b[0m 1s/step - loss: 1.4428\n",
      "Epoch 4/10\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m978s\u001b[0m 1s/step - loss: 1.4299\n",
      "Epoch 5/10\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m978s\u001b[0m 1s/step - loss: 1.2718\n",
      "Fine tunning: 5031.64 seconds\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 189ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Similar cards to Sol Ring:\n",
      "Sol Ring, (similarity: 1.00)\n",
      "Ur-Golem's Eye, (similarity: 0.99)\n",
      "Ur-Golem's Eye, (similarity: 0.99)\n",
      "Thran Dynamo, (similarity: 0.94)\n",
      "Wastes, (similarity: 0.93)\n",
      "Ancient Den, (similarity: 0.93)\n",
      "Vault of Whispers, (similarity: 0.93)\n",
      "Great Furnace, (similarity: 0.93)\n",
      "Pyretic Ritual, (similarity: 0.92)\n",
      "Tree of Tales, (similarity: 0.92)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Similar cards to Structural Assault:\n",
      "Structural Assault, (similarity: 1.00)\n",
      "Let the Galaxy Burn, (similarity: 0.96)\n",
      "Summer Bloom, (similarity: 0.94)\n",
      "Wish, (similarity: 0.94)\n",
      "Sangrite Surge, (similarity: 0.93)\n",
      "Wake the Past, (similarity: 0.92)\n",
      "Burn Down the House, (similarity: 0.92)\n",
      "Mass Mutiny, (similarity: 0.92)\n",
      "Insurrection, (similarity: 0.92)\n",
      "Soul Reap, (similarity: 0.92)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Similar cards to Crossbow Ambush:\n",
      "Shape the Sands, (similarity: 1.00)\n",
      "Silk Net, (similarity: 1.00)\n",
      "Vines of the Recluse, (similarity: 1.00)\n",
      "Crossbow Ambush, (similarity: 1.00)\n",
      "Silk Net, (similarity: 1.00)\n",
      "Aim High, (similarity: 0.98)\n",
      "Treetop Defense, (similarity: 0.98)\n",
      "Spidery Grasp, (similarity: 0.98)\n",
      "Gloomwidow's Feast, (similarity: 0.98)\n",
      "Cruel Feeding, (similarity: 0.96)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Similar cards to Mephitic Draught:\n",
      "Mephitic Draught, (similarity: 1.00)\n",
      "Metalspinner's Puzzleknot, (similarity: 1.00)\n",
      "Druidic Satchel, (similarity: 0.96)\n",
      "Infernal Idol, (similarity: 0.96)\n",
      "Profane Memento, (similarity: 0.95)\n",
      "Dragon's Claw, (similarity: 0.95)\n",
      "Altar of the Pantheon, (similarity: 0.94)\n",
      "Skullmead Cauldron, (similarity: 0.94)\n",
      "Tithing Blade // Consuming Sepulcher, (similarity: 0.94)\n",
      "Zuran Orb, (similarity: 0.94)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Similar cards to Sangromancer:\n",
      "Sangromancer, (similarity: 1.00)\n",
      "Bloodrite Invoker, (similarity: 0.99)\n",
      "Kalastria Highborn, (similarity: 0.94)\n",
      "Herald of the Pantheon, (similarity: 0.93)\n",
      "Waker of the Wilds, (similarity: 0.92)\n",
      "Erratic Cyclops, (similarity: 0.91)\n",
      "Malakir Bloodwitch, (similarity: 0.91)\n",
      "Blood Seeker, (similarity: 0.90)\n",
      "Vampire Nighthawk, (similarity: 0.90)\n",
      "World Shaper, (similarity: 0.90)\n",
      "Model: cnn_lstm\n",
      "Epoch 1/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m612s\u001b[0m 382ms/step - loss: 2.8769\n",
      "Epoch 2/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m609s\u001b[0m 381ms/step - loss: 2.2239\n",
      "Epoch 3/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m609s\u001b[0m 381ms/step - loss: 1.7925\n",
      "Epoch 4/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m609s\u001b[0m 381ms/step - loss: 1.5361\n",
      "Epoch 5/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m608s\u001b[0m 381ms/step - loss: 1.3351\n",
      "Training Time: 3046.66 seconds\n",
      "Fine tunning:\n",
      "Epoch 1/10\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 179ms/step - loss: 2.3787\n",
      "Epoch 2/10\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 179ms/step - loss: 1.8274\n",
      "Epoch 3/10\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 179ms/step - loss: 1.6424\n",
      "Epoch 4/10\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 180ms/step - loss: 1.5071\n",
      "Epoch 5/10\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 179ms/step - loss: 1.4670\n",
      "Fine tunning: 732.36 seconds\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Similar cards to Sol Ring:\n",
      "Sol Ring, (similarity: 1.00)\n",
      "Ur-Golem's Eye, (similarity: 0.99)\n",
      "Ur-Golem's Eye, (similarity: 0.99)\n",
      "Thran Dynamo, (similarity: 0.98)\n",
      "Bloodstone Cameo, (similarity: 0.96)\n",
      "Seashell Cameo, (similarity: 0.96)\n",
      "Troll-Horn Cameo, (similarity: 0.96)\n",
      "Drake-Skull Cameo, (similarity: 0.96)\n",
      "Great Furnace, (similarity: 0.95)\n",
      "Ancient Den, (similarity: 0.94)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Similar cards to Structural Assault:\n",
      "Structural Assault, (similarity: 1.00)\n",
      "Wish, (similarity: 0.94)\n",
      "Let the Galaxy Burn, (similarity: 0.93)\n",
      "Sangrite Surge, (similarity: 0.92)\n",
      "Storm the Seedcore, (similarity: 0.92)\n",
      "Cabaretti Confluence, (similarity: 0.92)\n",
      "Fit of Rage, (similarity: 0.92)\n",
      "Overrun, (similarity: 0.92)\n",
      "Volcanic Torrent, (similarity: 0.92)\n",
      "Flesh Allergy, (similarity: 0.91)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Similar cards to Crossbow Ambush:\n",
      "Vines of the Recluse, (similarity: 1.00)\n",
      "Silk Net, (similarity: 1.00)\n",
      "Crossbow Ambush, (similarity: 1.00)\n",
      "Silk Net, (similarity: 1.00)\n",
      "Shape the Sands, (similarity: 1.00)\n",
      "Spidery Grasp, (similarity: 0.99)\n",
      "Treetop Defense, (similarity: 0.99)\n",
      "Aim High, (similarity: 0.99)\n",
      "Gloomwidow's Feast, (similarity: 0.99)\n",
      "Rock Slide, (similarity: 0.96)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Similar cards to Mephitic Draught:\n",
      "Metalspinner's Puzzleknot, (similarity: 1.00)\n",
      "Mephitic Draught, (similarity: 1.00)\n",
      "Infernal Idol, (similarity: 0.98)\n",
      "Ivory Crane Netsuke, (similarity: 0.95)\n",
      "Dragon's Claw, (similarity: 0.95)\n",
      "Druidic Satchel, (similarity: 0.95)\n",
      "Scroll of Griselbrand, (similarity: 0.94)\n",
      "Skullmead Cauldron, (similarity: 0.94)\n",
      "Profane Memento, (similarity: 0.94)\n",
      "Graveyard Shovel, (similarity: 0.94)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Similar cards to Sangromancer:\n",
      "Sangromancer, (similarity: 1.00)\n",
      "Bloodrite Invoker, (similarity: 0.97)\n",
      "Kalastria Highborn, (similarity: 0.94)\n",
      "Sanctum Seeker, (similarity: 0.94)\n",
      "Guardian of Cloverdell, (similarity: 0.94)\n",
      "Deathgreeter, (similarity: 0.93)\n",
      "Bog-Strider Ash, (similarity: 0.93)\n",
      "Shattered Angel, (similarity: 0.93)\n",
      "Herald of the Pantheon, (similarity: 0.92)\n",
      "Blood Seeker, (similarity: 0.92)\n",
      "Model: transformer\n",
      "Epoch 1/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2519s\u001b[0m 2s/step - loss: 2.9790\n",
      "Epoch 2/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2522s\u001b[0m 2s/step - loss: 2.7779\n",
      "Epoch 3/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2525s\u001b[0m 2s/step - loss: 2.7640\n",
      "Epoch 4/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2531s\u001b[0m 2s/step - loss: 2.7015\n",
      "Epoch 5/40\n",
      "\u001b[1m1598/1598\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2555s\u001b[0m 2s/step - loss: 2.6242\n",
      "Training Time: 12652.47 seconds\n",
      "Fine tunning:\n",
      "Epoch 1/10\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 558ms/step - loss: 2.8886\n",
      "Epoch 2/10\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m451s\u001b[0m 552ms/step - loss: 2.3974\n",
      "Epoch 3/10\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m451s\u001b[0m 551ms/step - loss: 2.1454\n",
      "Epoch 4/10\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m451s\u001b[0m 552ms/step - loss: 2.0920\n",
      "Epoch 5/10\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 550ms/step - loss: 1.9889\n",
      "Fine tunning: 2257.16 seconds\n",
      "\u001b[1m817/817\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Similar cards to Sol Ring:\n",
      "Sol Ring, (similarity: 1.00)\n",
      "Ur-Golem's Eye, (similarity: 1.00)\n",
      "Ur-Golem's Eye, (similarity: 1.00)\n",
      "Seething Song, (similarity: 0.99)\n",
      "Dark Ritual, (similarity: 0.99)\n",
      "Thran Dynamo, (similarity: 0.99)\n",
      "Pyretic Ritual, (similarity: 0.99)\n",
      "Opt, (similarity: 0.98)\n",
      "Boros Signet, (similarity: 0.98)\n",
      "Rakdos Signet, (similarity: 0.98)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Similar cards to Structural Assault:\n",
      "Structural Assault, (similarity: 1.00)\n",
      "Call for Aid, (similarity: 1.00)\n",
      "Saltblast, (similarity: 1.00)\n",
      "Insurrection, (similarity: 1.00)\n",
      "Burn Down the House, (similarity: 1.00)\n",
      "Mass Mutiny, (similarity: 1.00)\n",
      "Providence, (similarity: 1.00)\n",
      "Song-Mad Treachery // Song-Mad Ruins, (similarity: 1.00)\n",
      "Press into Service, (similarity: 1.00)\n",
      "Single Combat, (similarity: 1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Similar cards to Crossbow Ambush:\n",
      "Silk Net, (similarity: 1.00)\n",
      "Shape the Sands, (similarity: 1.00)\n",
      "Silk Net, (similarity: 1.00)\n",
      "Crossbow Ambush, (similarity: 1.00)\n",
      "Vines of the Recluse, (similarity: 1.00)\n",
      "Deceive the Messenger, (similarity: 1.00)\n",
      "Choking Vines, (similarity: 1.00)\n",
      "Ebony Charm, (similarity: 1.00)\n",
      "Crowd's Favor, (similarity: 1.00)\n",
      "Lava Dart, (similarity: 1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Similar cards to Mephitic Draught:\n",
      "Metalspinner's Puzzleknot, (similarity: 1.00)\n",
      "Mephitic Draught, (similarity: 1.00)\n",
      "Conservator, (similarity: 1.00)\n",
      "Shield of the Ages, (similarity: 1.00)\n",
      "Tower of Calamities, (similarity: 1.00)\n",
      "Scrying Glass, (similarity: 1.00)\n",
      "Endless Atlas, (similarity: 1.00)\n",
      "Cosmos Elixir, (similarity: 1.00)\n",
      "Howling Mine, (similarity: 1.00)\n",
      "Moratorium Stone, (similarity: 1.00)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Similar cards to Sangromancer:\n",
      "Sangromancer, (similarity: 1.00)\n",
      "Bloodrite Invoker, (similarity: 1.00)\n",
      "Patron of the Vein, (similarity: 1.00)\n",
      "Pawn of Ulamog, (similarity: 1.00)\n",
      "Null Caller, (similarity: 1.00)\n",
      "Malakir Bloodwitch, (similarity: 1.00)\n",
      "Bloodhusk Ritualist, (similarity: 1.00)\n",
      "Vampire Hexmage, (similarity: 1.00)\n",
      "Bloodthirsty Ogre, (similarity: 1.00)\n",
      "Blood Seeker, (similarity: 1.00)\n"
     ]
    }
   ],
   "source": [
    "def compute_embeddings(descriptions):\n",
    "    sequences = tokenizer_card_descriptions.texts_to_sequences(descriptions)\n",
    "    padded_seqs = pad_sequences(sequences, maxlen=max_len_description, padding='post')\n",
    "    return encoder.predict(padded_seqs)\n",
    "\n",
    "def get_card_description(querry):\n",
    "    index = np.where(card_names == querry)[0]\n",
    "    if index.size > 0:\n",
    "        return card_descriptions[index][0]\n",
    "    return querry\n",
    "\n",
    "def get_card_name(querry):\n",
    "    card_index = np.where(card_descriptions == querry)[0][0]\n",
    "    return card_names[card_index]\n",
    "\n",
    "def find_similar_cards(querry, card_descriptions, card_embeddings, top_n=3):\n",
    "    card_description = get_card_description(querry)\n",
    "    query_embedding = compute_embeddings([card_description])[0]\n",
    "    similarities = cosine_similarity([query_embedding], card_embeddings)[0]\n",
    "    similar_indices = similarities.argsort()[-top_n:][::-1]\n",
    "    return [(card_descriptions[i], similarities[i]) for i in similar_indices]\n",
    "\n",
    "model_prediction_dict = {}\n",
    "\n",
    "for i in range(len(model_names)):\n",
    "    model_name = \"_\" + model_names[i]\n",
    "    autoencoder_name = model_names[i] + \"_autoencoder\"\n",
    "    encoder_name = model_names[i] + \"_encoder\"\n",
    "    model_function = model_functions[i]\n",
    "    autoencoder, encoder = model_function(vocab_size, max_len_description, embedding_dim)\n",
    "    # print(autoencoder.summary(), encoder.summary())\n",
    "    autoencoder.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "    \n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + model_name\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    print(f\"Model: {model_names[i]}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    autoencoder.fit(padded_sequences_sentences, target_padded_sequences_sentences, epochs=40, batch_size=128, callbacks=[early_stopping, tensorboard_callback])\n",
    "    end_time = time.time()\n",
    "    \n",
    "    training_time = end_time - start_time\n",
    "    print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "\n",
    "    print(\"Fine tunning:\")\n",
    "    start_time = time.time()\n",
    "    autoencoder.fit(padded_sequences_card_descriptions, target_padded_sequences_card_descriptions, epochs=10, batch_size=32, callbacks=[early_stopping, tensorboard_callback])\n",
    "    end_time = time.time()\n",
    "    \n",
    "    training_time = end_time - start_time\n",
    "    print(f\"Fine tunning: {training_time:.2f} seconds\")\n",
    "    \n",
    "    card_embeddings = compute_embeddings(card_descriptions)\n",
    "    model_predictions = {}\n",
    "    card_predictions = []\n",
    "\n",
    "    query_descriptions = ['Sol Ring', 'Structural Assault', 'Crossbow Ambush', 'Mephitic Draught', 'Sangromancer']\n",
    "    for query_description in query_descriptions:\n",
    "        similar_cards = find_similar_cards(query_description, card_descriptions, card_embeddings, 10)\n",
    "        print(f\"Similar cards to {query_description}:\")\n",
    "        for desc, score in similar_cards:        \n",
    "            card_predictions.append(get_card_name(desc))\n",
    "            print(f\"{get_card_name(desc)}, (similarity: {score:.2f})\")\n",
    "\n",
    "        model_predictions[query_description] = card_descriptions\n",
    "\n",
    "    model_prediction_dict[model_name] = model_predictions\n",
    "    save_model(autoencoder, autoencoder_name)\n",
    "    save_model(encoder, encoder_name)\n",
    "\n",
    "with open(\"card_predictions.json\", \"w\") as outfile: \n",
    "    json.dump(model_prediction_dict, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masters_degree_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
