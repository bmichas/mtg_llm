{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 13:17:06.818787: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-07 13:17:07.732290: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/weap/masters_degree/masters_degree_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Bidirectional, RepeatVector, Attention, Concatenate, Conv1D, MaxPooling1D, Concatenate, UpSampling1D, MultiHeadAttention, LayerNormalization, Add, GRU, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "from datasets import load_dataset\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"embedding-data/simple-wiki\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The greatest example has been in his present job ( then , Minister for Foreign Affairs ) , where he has perforce concentrated on Anglo-Irish relations and , in particular Northern Ireland ( .\n",
      "The greatest example has been in his present job ( then , Minister for Foreign Affairs ) , where he has perforce concentrated on Anglo-Irish relations and , in particular the North ( i.e. , Northern Ireland ) .\n",
      "President Hillery refused to speak to any opposition party politicians , but when Charles Haughey , who was Leader of the Opposition , had rang the President 's Office he threatened to end the career of the army officer answered and refused on Hillery 's explicit orders to put the call through to the President .\n",
      "His reputation rose further when opposition leaders under parliamentary privilege alleged that Taoiseach Charles Haughey , who in January 1982 had been Leader of the Opposition , had not merely rung the President 's Office but threatened to end the career of the army officer who took the call and who , on Hillery 's explicit instructions , had refused to put through the call to the President .\n",
      "He thought about returning to medicine , perhaps moving with his wife , Maeve ( also a doctor ) to Africa .\n",
      "He considered returning to medicine , perhaps moving with his wife , Maeve ( also a doctor ) to Africa .\n",
      "Hillery 's most famous policy was to force EEC member states to give equal pay to women .\n",
      "As Social Affairs Commissioner Hillery 's most famous policy initiative was to force EEC member states to give equal pay to women .\n",
      "When President Cearbhall Ã `` DÃ laigh resigned , Hillery agreed to become the Fianna FÃ il candidate in the election .\n",
      "When a furious President Ã `` DÃ laigh resigned , a deeply reluctant Hillery agreed to become the Fianna FÃ il candidate for the presidency .\n"
     ]
    }
   ],
   "source": [
    "train_data = dataset['train']\n",
    "sentences = [sentence for pair in train_data['set'] for sentence in pair]\n",
    "for i in range(10):\n",
    "    print(sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Tukatongue Thallid', 'Moriok Replica', 'Faerie Mechanist', ...,\n",
       "        'Mogg Squad', 'Roots of Wisdom', 'Raven Guild Master'],\n",
       "       dtype=object),\n",
       " array(['When Tukatongue Thallid dies, create a 1/1 green Saproling creature token.1.011Creature — Fungus',\n",
       "        '{1}{B}, Sacrifice Moriok Replica: You draw two cards and you lose 2 life.3.022Artifact Creature — Warrior',\n",
       "        'Flying\\nWhen Faerie Mechanist enters the battlefield, look at the top three cards of your library. You may reveal an artifact card from among them and put it into your hand. Put the rest on the bottom of your library in any order.4.022Artifact Creature — Faerie Artificer',\n",
       "        ...,\n",
       "        'Mogg Squad gets -1/-1 for each other creature on the battlefield.2.033Creature — Goblin',\n",
       "        \"Mill three cards, then return a land card or Elf card from your graveyard to your hand. If you can't, draw a card. (To mill a card, put the top card of your library into your graveyard.)2.0nannanSorcery\",\n",
       "        'Whenever Raven Guild Master deals combat damage to a player, that player exiles the top ten cards of their library.\\nMorph {2}{U}{U} (You may cast this card face down as a 2/2 creature for {3}. Turn it face up any time for its morph cost.)3.011Creature — Human Wizard Mutant'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = 'data_download/MyDataMTGv2.json'\n",
    "# filepath = 'data_download/clean_df.csv'\n",
    "\n",
    "# def load_dataset(path):\n",
    "#     df = pd.read_csv('data_download/clean_df.csv')\n",
    "#     df['text'] = df['text'].astype(str).fillna('text')\n",
    "#     df['manaCost'] = df['manaCost'].astype(str).fillna('manaCost')\n",
    "#     df['toughness'] = df['toughness'].astype(str).fillna('toughness')\n",
    "#     df['power'] = df['power'].astype(str).fillna('power')\n",
    "#     df['type'] = df['type'].astype(str).fillna('type')\n",
    "#     df['description'] = df['text'] + ' manaCost ' + df['manaCost'] + ' toughness ' + df['toughness'] + ' power ' + df['power'] + ' types ' + df['type']\n",
    "#     return df['card_name'].values, df['description'].values\n",
    "\n",
    "def load_dataset(path):\n",
    "    df = pd.read_json(path).T\n",
    "    df['text'] = df['text'].astype(str).fillna('text')\n",
    "    df['manaValue'] = df['manaValue'].astype(str).fillna('manaValue')\n",
    "    df['toughness'] = df['toughness'].astype(str).fillna('toughness')\n",
    "    df['power'] = df['power'].astype(str).fillna('power')\n",
    "    df['type'] = df['type'].astype(str).fillna('type')\n",
    "    df['description'] = df['text'] + '' + df['manaValue'] + '' + df['toughness'] + '' + df['power'] + '' + df['type']\n",
    "    df_filtered = df[['description']].reset_index()\n",
    "    df_filtered.rename(columns={'index': 'card_name'}, inplace=True)\n",
    "    return df_filtered['card_name'].values, df_filtered['description'].values\n",
    "\n",
    "card_names, card_descriptions = load_dataset(filepath)\n",
    "\n",
    "card_names, card_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 512\n",
    "max_len_description = 50 \n",
    "max_len_name = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and padding\n",
    "tokenizer_sentences = Tokenizer(char_level=True,\n",
    "                      lower=True,\n",
    "                      filters='!\"#$%&()*,.:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "                    #   filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "\n",
    "tokenizer_card_descriptions= Tokenizer(char_level=True,\n",
    "                             lower=True,\n",
    "                             filters='!\"#$%&()*,.:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "                    #   filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "\n",
    "tokenizer_sentences.fit_on_texts(sentences)\n",
    "sequences_sentences = tokenizer_sentences.texts_to_sequences(sentences)\n",
    "padded_sequences_sentences = pad_sequences(sequences_sentences, maxlen=max_len_description, padding='post')\n",
    "\n",
    "tokenizer_card_descriptions.fit_on_texts(card_descriptions)\n",
    "sequences_card_descriptions = tokenizer_card_descriptions.texts_to_sequences(card_descriptions)\n",
    "padded_sequences_card_descriptions = pad_sequences(sequences_card_descriptions, maxlen=max_len_description, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer_sentences.word_index) + 1  # Plus 1 for padding\n",
    "\n",
    "padded_sequences_sentences = np.array(padded_sequences_sentences)\n",
    "target_padded_sequences_sentences= np.expand_dims(padded_sequences_sentences, -1)\n",
    "\n",
    "padded_sequences_card_descriptions = np.array(padded_sequences_card_descriptions)\n",
    "target_padded_sequences_card_descriptions= np.expand_dims(padded_sequences_card_descriptions, -1)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tokenizer(tokenizer, path='./models_colab/tokenizer.pkl'):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(tokenizer, f)\n",
    "\n",
    "def load_tokenizer(path='./models_colab/tokenizer_transformer.pkl'):\n",
    "    with open(path, 'rb') as f:\n",
    "        tokenizer = pickle.load(f)\n",
    "    return tokenizer\n",
    "\n",
    "# save_tokenizer(tokenizer_card_descriptions)\n",
    "# tokenizer_card_descriptions = load_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, name, path='./models'):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    model.save(os.path.join(path, f\"{name}.keras\"))\n",
    "\n",
    "def load_model(name, path='./models_colab'):\n",
    "    return tf.keras.models.load_model(os.path.join(path, f\"{name}.keras\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(vocab_size, input_length, embedding_dim):\n",
    "    # Encoder\n",
    "    input_text = Input(shape=(input_length,))\n",
    "    x = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_text)\n",
    "    x = LSTM(embedding_dim, return_sequences=False)(x)\n",
    "    \n",
    "    # Dense layer as the \"bottleneck\" embedding (this is our sentence embedding)\n",
    "    encoded = Dense(embedding_dim, activation='relu')(x)\n",
    "    \n",
    "    # Decoder\n",
    "    x = Dense(embedding_dim, activation='relu')(encoded)\n",
    "    x = tf.keras.layers.RepeatVector(input_length)(x)\n",
    "    x = LSTM(embedding_dim, return_sequences=True)(x)\n",
    "    decoded = Dense(vocab_size, activation='softmax')(x)\n",
    "    \n",
    "    # Autoencoder model\n",
    "    autoencoder = Model(inputs=input_text, outputs=decoded)\n",
    "    \n",
    "    # Encoder model (for extracting embeddings)\n",
    "    encoder = Model(inputs=input_text, outputs=encoded)\n",
    "    \n",
    "    return autoencoder, encoder\n",
    "\n",
    "def create_lstm_bilstm(vocab_size, input_length, embedding_dim):\n",
    "    # Input for both encoders\n",
    "    input_text = Input(shape=(input_length,))\n",
    "    \n",
    "    # BiLSTM Encoder\n",
    "    x1 = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_text)\n",
    "    x1 = Bidirectional(LSTM(embedding_dim, return_sequences=False))(x1)\n",
    "    encoded1 = Dense(embedding_dim, activation='relu')(x1)\n",
    "\n",
    "    # LSTM Encoder\n",
    "    x2 = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_text)\n",
    "    x2 = LSTM(embedding_dim, return_sequences=False)(x2)\n",
    "    encoded2 = Dense(embedding_dim, activation='relu')(x2)\n",
    "\n",
    "    # Combine Encodings\n",
    "    combined_encoding = Concatenate()([encoded1, encoded2])\n",
    "\n",
    "    # Decoder\n",
    "    x = Dense(embedding_dim * 2, activation='relu')(combined_encoding)  # Adjust for doubled embedding dimension\n",
    "    x = RepeatVector(input_length)(x)\n",
    "    x = LSTM(embedding_dim * 2, return_sequences=True)(x)\n",
    "    decoded = Dense(vocab_size, activation='softmax')(x)\n",
    "\n",
    "    # Models\n",
    "    autoencoder = Model(inputs=input_text, outputs=decoded)\n",
    "    encoder = Model(inputs=input_text, outputs=combined_encoding)\n",
    "\n",
    "    return autoencoder, encoder\n",
    "\n",
    "def create_bilstm_autoencoder(vocab_size, input_length, embedding_dim):\n",
    "    # Encoder\n",
    "    input_text = Input(shape=(input_length,))\n",
    "    x = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_text)\n",
    "    x = Bidirectional(LSTM(embedding_dim, return_sequences=False))(x)\n",
    "    \n",
    "    # Bottleneck\n",
    "    encoded = Dense(embedding_dim, activation='relu')(x)\n",
    "    \n",
    "    # Decoder\n",
    "    x = Dense(embedding_dim, activation='relu')(encoded)\n",
    "    x = RepeatVector(input_length)(x)\n",
    "    x = Bidirectional(LSTM(embedding_dim, return_sequences=True))(x)\n",
    "    decoded = Dense(vocab_size, activation='softmax')(x)\n",
    "    \n",
    "    # Models\n",
    "    autoencoder = Model(inputs=input_text, outputs=decoded)\n",
    "    encoder = Model(inputs=input_text, outputs=encoded)\n",
    "    \n",
    "    return autoencoder, encoder\n",
    "\n",
    "\n",
    "def create_bilstm_autoencoder_attention(vocab_size, input_length, embedding_dim):\n",
    "    # Encoder\n",
    "    input_text = Input(shape=(input_length,))\n",
    "    x = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_text)\n",
    "    \n",
    "    # Bidirectional LSTM for richer context encoding\n",
    "    x = Bidirectional(LSTM(embedding_dim, return_sequences=True))(x)\n",
    "    \n",
    "    # Adding a Dropout layer to prevent overfitting\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # Attention layer to focus on important words for MTG cards\n",
    "    # We calculate attention on the output of the LSTM\n",
    "    attention = Attention()([x, x])\n",
    "    x = Concatenate()([x, attention])  # Concatenate original LSTM output with attention output\n",
    "    \n",
    "    # Final dense layer as bottleneck embedding (sentence embedding)\n",
    "    x = LSTM(embedding_dim, return_sequences=False)(x)  # Flatten output for dense layer\n",
    "    encoded = Dense(embedding_dim, activation='relu')(x)\n",
    "    \n",
    "    # Decoder\n",
    "    x = Dense(embedding_dim, activation='relu')(encoded)\n",
    "    x = RepeatVector(input_length)(x)\n",
    "    \n",
    "    # Second LSTM layer for decoding\n",
    "    x = Bidirectional(LSTM(embedding_dim, return_sequences=True))(x)\n",
    "    x = Dropout(0.2)(x)  # Dropout in decoder for robustness\n",
    "    \n",
    "    # Final output layer with softmax activation\n",
    "    decoded = Dense(vocab_size, activation='softmax')(x)\n",
    "    \n",
    "    # Autoencoder model\n",
    "    autoencoder = Model(inputs=input_text, outputs=decoded)\n",
    "    \n",
    "    # Encoder model (for extracting embeddings)\n",
    "    encoder = Model(inputs=input_text, outputs=encoded)\n",
    "    \n",
    "    return autoencoder, encoder\n",
    "\n",
    "\n",
    "def create_cnn_lstm_autoencoder(vocab_size, input_length, embedding_dim):\n",
    "    # Encoder\n",
    "    input_text = Input(shape=(input_length,))\n",
    "    x = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_text)\n",
    "    x = Conv1D(embedding_dim, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = LSTM(embedding_dim, return_sequences=False)(x)\n",
    "    \n",
    "    # Bottleneck\n",
    "    encoded = Dense(embedding_dim, activation='relu')(x)\n",
    "    \n",
    "    # Decoder\n",
    "    x = Dense(embedding_dim, activation='relu')(encoded)\n",
    "    x = RepeatVector(input_length // 2)(x)\n",
    "    x = LSTM(embedding_dim, return_sequences=True)(x)\n",
    "    x = UpSampling1D(size=2)(x)\n",
    "    decoded = Dense(vocab_size, activation='softmax')(x)\n",
    "    \n",
    "    # Models\n",
    "    autoencoder = Model(inputs=input_text, outputs=decoded)\n",
    "    encoder = Model(inputs=input_text, outputs=encoded)\n",
    "    \n",
    "    return autoencoder, encoder\n",
    "\n",
    "\n",
    "def transformer_encoder_decoder(vocab_size, input_length, embedding_dim, num_heads=4, dropout_rate=0.1):\n",
    "    # Positional Embedding Layer\n",
    "    class PositionalEmbedding(Layer):\n",
    "        def __init__(self, vocab_size, embedding_dim, input_length):\n",
    "            super(PositionalEmbedding, self).__init__()\n",
    "            self.embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim)\n",
    "            self.positional_encoding = self.add_weight(\n",
    "                shape=(input_length, embedding_dim), initializer=\"zeros\", trainable=True\n",
    "            )\n",
    "        \n",
    "        def call(self, inputs):\n",
    "            seq_length = tf.shape(inputs)[1]\n",
    "            return self.embedding(inputs) + self.positional_encoding[:seq_length]\n",
    "\n",
    "    # Encoder\n",
    "    input_text = Input(shape=(input_length,))\n",
    "    x = PositionalEmbedding(vocab_size, embedding_dim, input_length)(input_text)\n",
    "    for _ in range(2):  # Stacking lightweight attention layers\n",
    "        attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim)(x, x)\n",
    "        x = LayerNormalization()(Add()([x, attn_output]))\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "    x = GRU(embedding_dim, return_sequences=False)(x)\n",
    "    \n",
    "    # Bottleneck\n",
    "    encoded = Dense(embedding_dim // 2, activation='relu')(x)\n",
    "    encoded = Dense(embedding_dim, activation='relu')(encoded)\n",
    "\n",
    "    # Decoder\n",
    "    x = Dense(embedding_dim, activation='relu')(encoded)\n",
    "    x = RepeatVector(input_length)(x)\n",
    "    for _ in range(2):  # Reuse GRU with shared layers\n",
    "        x = GRU(embedding_dim, return_sequences=True)(x)\n",
    "        x = LayerNormalization()(x)\n",
    "    decoded = Dense(vocab_size, activation='softmax')(x)\n",
    "\n",
    "    # Models\n",
    "    autoencoder = Model(inputs=input_text, outputs=decoded)\n",
    "    encoder = Model(inputs=input_text, outputs=encoded)\n",
    "\n",
    "    return autoencoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss',    \n",
    "    patience=5,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_names = [\"lstm\", \"bilstm\", \"lstm_bilstm\", \"bilstm_attention\", \"cnn_lstm\", \"transformer\"]\n",
    "model_names = [\"lstm\", \"cnn_lstm\"]\n",
    "# model_names = [\"transformer\"]\n",
    "# model_functions = [create_lstm_model, create_bilstm_autoencoder, create_lstm_bilstm, create_bilstm_autoencoder_attention, create_cnn_lstm_autoencoder, transformer_encoder_decoder]\n",
    "model_functions = [create_lstm_model, create_cnn_lstm_autoencoder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">48,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">95</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">48,735</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │        \u001b[38;5;34m48,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m2,099,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector_1 (\u001b[38;5;33mRepeatVector\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │     \u001b[38;5;34m2,099,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m95\u001b[0m)         │        \u001b[38;5;34m48,735\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,463,263</span> (55.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,463,263\u001b[0m (55.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,821,087</span> (18.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,821,087\u001b[0m (18.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,642,176</span> (36.78 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m9,642,176\u001b[0m (36.78 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">48,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │        \u001b[38;5;34m48,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m2,099,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,410,496</span> (9.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,410,496\u001b[0m (9.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,410,496</span> (9.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,410,496\u001b[0m (9.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None\n",
      "\u001b[1m 27/817\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 34ms/step"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 56\u001b[0m\n\u001b[1;32m     35\u001b[0m autoencoder\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + model_name\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# print(f\"Model: {model_names[i]}\")\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# training_time = end_time - start_time\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# print(f\"Fine tunning time: {training_time:.2f} seconds\")\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m card_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcard_descriptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m query_descriptions \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSol Ring\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStructural Assault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCrossbow Ambush\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMephitic Draught\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSangromancer\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m query_description \u001b[38;5;129;01min\u001b[39;00m query_descriptions:\n",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m, in \u001b[0;36mcompute_embeddings\u001b[0;34m(descriptions)\u001b[0m\n\u001b[1;32m      2\u001b[0m sequences \u001b[38;5;241m=\u001b[39m tokenizer_card_descriptions\u001b[38;5;241m.\u001b[39mtexts_to_sequences(descriptions)\n\u001b[1;32m      3\u001b[0m padded_seqs \u001b[38;5;241m=\u001b[39m pad_sequences(sequences, maxlen\u001b[38;5;241m=\u001b[39mmax_len_description, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadded_seqs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/masters_degree/masters_degree_env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/masters_degree/masters_degree_env/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:504\u001b[0m, in \u001b[0;36mTensorFlowTrainer.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    502\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[1;32m    503\u001b[0m data \u001b[38;5;241m=\u001b[39m get_data(iterator)\n\u001b[0;32m--> 504\u001b[0m batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m outputs \u001b[38;5;241m=\u001b[39m append_to_outputs(batch_outputs, outputs)\n\u001b[1;32m    506\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_end(step, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: batch_outputs})\n",
      "File \u001b[0;32m~/masters_degree/masters_degree_env/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/masters_degree/masters_degree_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/masters_degree/masters_degree_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/masters_degree/masters_degree_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/masters_degree/masters_degree_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/masters_degree/masters_degree_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/masters_degree/masters_degree_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/masters_degree/masters_degree_env/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/masters_degree/masters_degree_env/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def compute_embeddings(descriptions):\n",
    "    sequences = tokenizer_card_descriptions.texts_to_sequences(descriptions)\n",
    "    padded_seqs = pad_sequences(sequences, maxlen=max_len_description, padding='post')\n",
    "    return encoder.predict(padded_seqs)\n",
    "\n",
    "def get_card_description(querry):\n",
    "    index = np.where(card_names == querry)[0]\n",
    "    if index.size > 0:\n",
    "        return card_descriptions[index][0]\n",
    "    \n",
    "    return querry\n",
    "\n",
    "def get_card_name(querry):\n",
    "    card_index = np.where(card_descriptions == querry)[0][0]\n",
    "    return card_names[card_index]\n",
    "\n",
    "def find_similar_cards(querry, card_descriptions, card_embeddings, top_n=3):\n",
    "    card_description = get_card_description(querry)\n",
    "    query_embedding = compute_embeddings([card_description])[0]\n",
    "    similarities = cosine_similarity([query_embedding], card_embeddings)[0]\n",
    "    similar_indices = similarities.argsort()[-top_n:][::-1]\n",
    "    return [(card_descriptions[i], similarities[i]) for i in similar_indices]\n",
    "\n",
    "model_predictions = []\n",
    "\n",
    "for i in range(len(model_names)):\n",
    "    model_name = \"_\" + model_names[i]\n",
    "    autoencoder_name = model_names[i] + \"_autoencoder\"\n",
    "    encoder_name = model_names[i] + \"_encoder\"\n",
    "    model_function = model_functions[i]\n",
    "    autoencoder, encoder = model_function(vocab_size, max_len_description, embedding_dim)\n",
    "    autoencoder = load_model(autoencoder_name)\n",
    "    encoder = load_model(encoder_name)\n",
    "    print(autoencoder.summary(), encoder.summary())\n",
    "    autoencoder.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "    \n",
    "    # log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + model_name\n",
    "    # tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    # print(f\"Model: {model_names[i]}\")\n",
    "    \n",
    "    # start_time = time.time()\n",
    "    # autoencoder.fit(padded_sequences_sentences, target_padded_sequences_sentences, epochs=60, batch_size=128, callbacks=[early_stopping, tensorboard_callback])\n",
    "    # # autoencoder.fit(padded_sequences_sentences, target_padded_sequences_sentences, epochs=1, batch_size=128, callbacks=[early_stopping])\n",
    "    # end_time = time.time()\n",
    "    # training_time = end_time - start_time\n",
    "    # print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "\n",
    "    # print(\"Fine tunning:\")\n",
    "    # start_time = time.time()\n",
    "    # autoencoder.fit(padded_sequences_card_descriptions, target_padded_sequences_card_descriptions, epochs=20, batch_size=32, callbacks=[early_stopping, tensorboard_callback])\n",
    "    # # autoencoder.fit(padded_sequences_card_descriptions, target_padded_sequences_card_descriptions, epochs=1, batch_size=32, callbacks=[early_stopping])\n",
    "    # end_time = time.time()\n",
    "    # training_time = end_time - start_time\n",
    "    # print(f\"Fine tunning time: {training_time:.2f} seconds\")\n",
    "    \n",
    "    card_embeddings = compute_embeddings(card_descriptions)\n",
    "    query_descriptions = ['Sol Ring', 'Structural Assault', 'Crossbow Ambush', 'Mephitic Draught', 'Sangromancer']\n",
    "    for query_description in query_descriptions:\n",
    "        card_predictions = [model_names[i], query_description]\n",
    "        similar_cards = find_similar_cards(query_description, card_descriptions, card_embeddings, 10)\n",
    "        for desc, score in similar_cards:        \n",
    "            card_predictions.append(get_card_name(desc))\n",
    "\n",
    "        model_predictions.append(card_predictions)\n",
    "\n",
    "\n",
    "    # save_model(autoencoder, autoencoder_name)\n",
    "    # save_model(encoder, encoder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Card Name</th>\n",
       "      <th>Similar Card 1</th>\n",
       "      <th>Similar Card 2</th>\n",
       "      <th>Similar Card 3</th>\n",
       "      <th>Similar Card 4</th>\n",
       "      <th>Similar Card 5</th>\n",
       "      <th>Similar Card 6</th>\n",
       "      <th>Similar Card 7</th>\n",
       "      <th>Similar Card 8</th>\n",
       "      <th>Similar Card 9</th>\n",
       "      <th>Similar Card 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm</td>\n",
       "      <td>Sol Ring</td>\n",
       "      <td>Sol Ring</td>\n",
       "      <td>Ur-Golem's Eye</td>\n",
       "      <td>Ur-Golem's Eye</td>\n",
       "      <td>Thran Dynamo</td>\n",
       "      <td>Wastes</td>\n",
       "      <td>Riverglide Pathway // Lavaglide Pathway</td>\n",
       "      <td>Riverglide Pathway // Lavaglide Pathway</td>\n",
       "      <td>Barkchannel Pathway // Tidechannel Pathway</td>\n",
       "      <td>Barkchannel Pathway // Tidechannel Pathway</td>\n",
       "      <td>Great Furnace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lstm</td>\n",
       "      <td>Structural Assault</td>\n",
       "      <td>Structural Assault</td>\n",
       "      <td>Thrilling Encore</td>\n",
       "      <td>Urborg Justice</td>\n",
       "      <td>Fresh Meat</td>\n",
       "      <td>Faith's Reward</td>\n",
       "      <td>Second Sunrise</td>\n",
       "      <td>Let the Galaxy Burn</td>\n",
       "      <td>Fatal Push</td>\n",
       "      <td>Cradle to Grave</td>\n",
       "      <td>Force of Despair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstm</td>\n",
       "      <td>Crossbow Ambush</td>\n",
       "      <td>Silk Net</td>\n",
       "      <td>Vines of the Recluse</td>\n",
       "      <td>Shape the Sands</td>\n",
       "      <td>Crossbow Ambush</td>\n",
       "      <td>Silk Net</td>\n",
       "      <td>Gloomwidow's Feast</td>\n",
       "      <td>Spidery Grasp</td>\n",
       "      <td>Aim High</td>\n",
       "      <td>Treetop Defense</td>\n",
       "      <td>Aerial Volley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lstm</td>\n",
       "      <td>Mephitic Draught</td>\n",
       "      <td>Metalspinner's Puzzleknot</td>\n",
       "      <td>Mephitic Draught</td>\n",
       "      <td>Infernal Idol</td>\n",
       "      <td>Skeletal Scrying</td>\n",
       "      <td>Cut of the Profits</td>\n",
       "      <td>Wooden Sphere</td>\n",
       "      <td>Tablet of Epityr</td>\n",
       "      <td>Urza's Chalice</td>\n",
       "      <td>Crystal Rod</td>\n",
       "      <td>Soul Net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lstm</td>\n",
       "      <td>Sangromancer</td>\n",
       "      <td>Sangromancer</td>\n",
       "      <td>Bloodrite Invoker</td>\n",
       "      <td>Kalastria Highborn</td>\n",
       "      <td>Sanctum Seeker</td>\n",
       "      <td>Herald of the Pantheon</td>\n",
       "      <td>Acolyte of Aclazotz</td>\n",
       "      <td>High Fae Negotiator</td>\n",
       "      <td>Judge of Currents</td>\n",
       "      <td>Inspiring Cleric</td>\n",
       "      <td>Centaur Healer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cnn_lstm</td>\n",
       "      <td>Sol Ring</td>\n",
       "      <td>Sol Ring</td>\n",
       "      <td>Ur-Golem's Eye</td>\n",
       "      <td>Ur-Golem's Eye</td>\n",
       "      <td>Thran Dynamo</td>\n",
       "      <td>Bloodstone Cameo</td>\n",
       "      <td>Seashell Cameo</td>\n",
       "      <td>Troll-Horn Cameo</td>\n",
       "      <td>Drake-Skull Cameo</td>\n",
       "      <td>Great Furnace</td>\n",
       "      <td>Wastes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cnn_lstm</td>\n",
       "      <td>Structural Assault</td>\n",
       "      <td>Structural Assault</td>\n",
       "      <td>Let the Galaxy Burn</td>\n",
       "      <td>Mordor on the March</td>\n",
       "      <td>Fiery Encore</td>\n",
       "      <td>All of History, All at Once</td>\n",
       "      <td>Empty the Warrens</td>\n",
       "      <td>Urban Evolution</td>\n",
       "      <td>Escape to the Wilds</td>\n",
       "      <td>Flesh Allergy</td>\n",
       "      <td>Galvanic Relay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cnn_lstm</td>\n",
       "      <td>Crossbow Ambush</td>\n",
       "      <td>Crossbow Ambush</td>\n",
       "      <td>Shape the Sands</td>\n",
       "      <td>Vines of the Recluse</td>\n",
       "      <td>Silk Net</td>\n",
       "      <td>Silk Net</td>\n",
       "      <td>Gloomwidow's Feast</td>\n",
       "      <td>Treetop Defense</td>\n",
       "      <td>Aim High</td>\n",
       "      <td>Spidery Grasp</td>\n",
       "      <td>Angelic Ascension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cnn_lstm</td>\n",
       "      <td>Mephitic Draught</td>\n",
       "      <td>Metalspinner's Puzzleknot</td>\n",
       "      <td>Mephitic Draught</td>\n",
       "      <td>Infernal Idol</td>\n",
       "      <td>Profane Memento</td>\n",
       "      <td>Tithing Blade // Consuming Sepulcher</td>\n",
       "      <td>Thopter Foundry</td>\n",
       "      <td>Druidic Satchel</td>\n",
       "      <td>Ivory Crane Netsuke</td>\n",
       "      <td>Guild Globe</td>\n",
       "      <td>Sphere of the Suns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cnn_lstm</td>\n",
       "      <td>Sangromancer</td>\n",
       "      <td>Sangromancer</td>\n",
       "      <td>Bloodrite Invoker</td>\n",
       "      <td>Kalastria Highborn</td>\n",
       "      <td>Shattered Angel</td>\n",
       "      <td>Herald of the Pantheon</td>\n",
       "      <td>Deathgreeter</td>\n",
       "      <td>Bog-Strider Ash</td>\n",
       "      <td>Guardian of Cloverdell</td>\n",
       "      <td>Blood Seeker</td>\n",
       "      <td>Bleak Coven Vampires</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Name           Card Name             Similar Card 1  \\\n",
       "0       lstm            Sol Ring                   Sol Ring   \n",
       "1       lstm  Structural Assault         Structural Assault   \n",
       "2       lstm     Crossbow Ambush                   Silk Net   \n",
       "3       lstm    Mephitic Draught  Metalspinner's Puzzleknot   \n",
       "4       lstm        Sangromancer               Sangromancer   \n",
       "5   cnn_lstm            Sol Ring                   Sol Ring   \n",
       "6   cnn_lstm  Structural Assault         Structural Assault   \n",
       "7   cnn_lstm     Crossbow Ambush            Crossbow Ambush   \n",
       "8   cnn_lstm    Mephitic Draught  Metalspinner's Puzzleknot   \n",
       "9   cnn_lstm        Sangromancer               Sangromancer   \n",
       "\n",
       "         Similar Card 2        Similar Card 3    Similar Card 4  \\\n",
       "0        Ur-Golem's Eye        Ur-Golem's Eye      Thran Dynamo   \n",
       "1      Thrilling Encore        Urborg Justice        Fresh Meat   \n",
       "2  Vines of the Recluse       Shape the Sands   Crossbow Ambush   \n",
       "3      Mephitic Draught         Infernal Idol  Skeletal Scrying   \n",
       "4     Bloodrite Invoker    Kalastria Highborn    Sanctum Seeker   \n",
       "5        Ur-Golem's Eye        Ur-Golem's Eye      Thran Dynamo   \n",
       "6   Let the Galaxy Burn   Mordor on the March      Fiery Encore   \n",
       "7       Shape the Sands  Vines of the Recluse          Silk Net   \n",
       "8      Mephitic Draught         Infernal Idol   Profane Memento   \n",
       "9     Bloodrite Invoker    Kalastria Highborn   Shattered Angel   \n",
       "\n",
       "                         Similar Card 5  \\\n",
       "0                                Wastes   \n",
       "1                        Faith's Reward   \n",
       "2                              Silk Net   \n",
       "3                    Cut of the Profits   \n",
       "4                Herald of the Pantheon   \n",
       "5                      Bloodstone Cameo   \n",
       "6           All of History, All at Once   \n",
       "7                              Silk Net   \n",
       "8  Tithing Blade // Consuming Sepulcher   \n",
       "9                Herald of the Pantheon   \n",
       "\n",
       "                            Similar Card 6  \\\n",
       "0  Riverglide Pathway // Lavaglide Pathway   \n",
       "1                           Second Sunrise   \n",
       "2                       Gloomwidow's Feast   \n",
       "3                            Wooden Sphere   \n",
       "4                      Acolyte of Aclazotz   \n",
       "5                           Seashell Cameo   \n",
       "6                        Empty the Warrens   \n",
       "7                       Gloomwidow's Feast   \n",
       "8                          Thopter Foundry   \n",
       "9                             Deathgreeter   \n",
       "\n",
       "                            Similar Card 7  \\\n",
       "0  Riverglide Pathway // Lavaglide Pathway   \n",
       "1                      Let the Galaxy Burn   \n",
       "2                            Spidery Grasp   \n",
       "3                         Tablet of Epityr   \n",
       "4                      High Fae Negotiator   \n",
       "5                         Troll-Horn Cameo   \n",
       "6                          Urban Evolution   \n",
       "7                          Treetop Defense   \n",
       "8                          Druidic Satchel   \n",
       "9                          Bog-Strider Ash   \n",
       "\n",
       "                               Similar Card 8  \\\n",
       "0  Barkchannel Pathway // Tidechannel Pathway   \n",
       "1                                  Fatal Push   \n",
       "2                                    Aim High   \n",
       "3                              Urza's Chalice   \n",
       "4                           Judge of Currents   \n",
       "5                           Drake-Skull Cameo   \n",
       "6                         Escape to the Wilds   \n",
       "7                                    Aim High   \n",
       "8                         Ivory Crane Netsuke   \n",
       "9                      Guardian of Cloverdell   \n",
       "\n",
       "                               Similar Card 9       Similar Card 10  \n",
       "0  Barkchannel Pathway // Tidechannel Pathway         Great Furnace  \n",
       "1                             Cradle to Grave      Force of Despair  \n",
       "2                             Treetop Defense         Aerial Volley  \n",
       "3                                 Crystal Rod              Soul Net  \n",
       "4                            Inspiring Cleric        Centaur Healer  \n",
       "5                               Great Furnace                Wastes  \n",
       "6                               Flesh Allergy        Galvanic Relay  \n",
       "7                               Spidery Grasp     Angelic Ascension  \n",
       "8                                 Guild Globe    Sphere of the Suns  \n",
       "9                                Blood Seeker  Bleak Coven Vampires  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['Model Name', 'Card Name'] + [f'Similar Card {i+1}' for i in range(10)]\n",
    "df = pd.DataFrame(model_predictions, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = 'similar_cards.csv'\n",
    "df.to_csv(output_filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masters_degree_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
